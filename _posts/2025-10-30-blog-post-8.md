---
title: 'Blog 8:  Harms in Machine Learning'
date: 2025-10-30
permalink: /posts/2025/10/blog-post-8/
tags:
  - T2I AI
  - South Asia
  - Society
  - Qualitative Research
---

**Case Study:**  
[Understanding Potential Sources of Harm throughout the Machine Learning Life Cycle](https://mit-serc.pubpub.org/pub/potential-sources-of-harm-throughout-the-machine-learning-life-cycle/release/2)

In today's blog I reflect on perhaps the most critical case study so far. The reason is because it goes over the root of all of the AI systems we see today. Machine learning is at the core of AI develoment and involves a lengthy process of training based on human data. One of the topics the authors of the case study discuss is the sources of harm the Machine Learning pipeline (the process of designing, developing and deploying a machine learning model).

At the beginning of the process, there is always a risk of historical bias in the data we are using to train a ML model. The world as it is is heavily biased and every real-world data comes with those biases embedded in it. One of those biases is about reinforcing certain preexisting stereotypes against a particular group. For example, imagine you want to train a machine learning model that detects the geographical location of a place based on an outdoor picture. The resulting model is more likely to be accurate when it comes to pinpointing locations in the western world because most people here have access to a smartphone to capture high quality pictures. However, the ML model might not be so lucky in localizing pictures in remote mountainous areas in Africa and instead might guess that the picture is in some caribbean islands, some of the most-visited touristic destinations. The reason for this is because the majority of the population in remote areas in Africa do not have access to smartphones that take pictures so the only pictures that the dataset might get are the ones in urban areas which do not resemble the whole Africa. This example highlights how ML models can oversimplify complex geographies simply because the data that it has been fed represent only one group of a certain location.